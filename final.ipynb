{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1d6e7-27c7-4f3d-887b-6ab2db299729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Efficiently extract data by processing line-by-line\n",
    "def extract_data(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    sentence = None\n",
    "    label_set = []\n",
    "\n",
    "    sentence_pattern = re.compile(r\"([A-Z][^.!?]*[.!?])\")\n",
    "    label_pattern = re.compile(r\"(ARG1|REL|ARG2|NONE|LOC|TIME)(\\s+\\w+)*\")\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if sentence_pattern.match(line):\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label_set)\n",
    "                    label_set = []\n",
    "                sentence = line\n",
    "            elif label_pattern.match(line):\n",
    "                label_set.append(line.split())\n",
    "\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label_set)\n",
    "\n",
    "    return sentences, labels\n",
    "\n",
    "# Vocabulary building and encoding\n",
    "def build_vocab(sentences, labels):\n",
    "    word2idx = {'<PAD>': 0}  # Initialize with <PAD> token\n",
    "    tag2idx = {}\n",
    "\n",
    "    # Build vocabulary for words\n",
    "    for sentence in sentences:\n",
    "        for word in sentence.split():\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(word2idx)\n",
    "\n",
    "    # Build vocabulary for tags (ARG1, REL, ARG2, etc.)\n",
    "    for label_set in labels:\n",
    "        for label_seq in label_set:\n",
    "            for label in label_seq:\n",
    "                if label not in tag2idx:\n",
    "                    tag2idx[label] = len(tag2idx)\n",
    "\n",
    "    return word2idx, tag2idx\n",
    "\n",
    "def encode_sentence(sentence, word2idx):\n",
    "    return [word2idx[word] for word in sentence.split()]\n",
    "\n",
    "def encode_labels(label_set, tag2idx):\n",
    "    return [tag2idx[label] for label_seq in label_set for label in label_seq]\n",
    "\n",
    "# Padding function\n",
    "def pad_and_convert_to_tensor(sequences, padding_value=0):\n",
    "    return pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=padding_value)\n",
    "\n",
    "# Truncate sequences function\n",
    "def truncate_sequences(sequences, max_len):\n",
    "    return [seq[:max_len] for seq in sequences]\n",
    "\n",
    "# Function to calculate class distribution in labels\n",
    "def calculate_label_distribution(labels, tag2idx):\n",
    "    label_counts = Counter()\n",
    "    for label_seq in labels:\n",
    "        label_counts.update(label_seq)\n",
    "    return {idx: label_counts.get(tag2idx[idx], 0) for idx in tag2idx}\n",
    "\n",
    "# Function to balance the dataset by undersampling frequent labels and/or oversampling minority labels\n",
    "def balance_dataset(sentences, labels, label_distribution, target_count_per_class):\n",
    "    balanced_sentences = []\n",
    "    balanced_labels = []\n",
    "\n",
    "    class_counts = {label: 0 for label in label_distribution}\n",
    "\n",
    "    for sentence, label_set in zip(sentences, labels):\n",
    "        for label_seq in label_set:\n",
    "            for label in label_seq:\n",
    "                if class_counts[label] < target_count_per_class:\n",
    "                    balanced_sentences.append(sentence)\n",
    "                    balanced_labels.append(label_set)\n",
    "                    class_counts[label] += 1\n",
    "\n",
    "    return balanced_sentences, balanced_labels\n",
    "\n",
    "# Dataloader preparation\n",
    "def prepare_dataloaders(encoded_sentences, encoded_labels, batch_size=32):\n",
    "    padded_sentences = pad_and_convert_to_tensor(encoded_sentences, padding_value=word2idx['<PAD>'])\n",
    "    padded_labels = pad_and_convert_to_tensor(encoded_labels, padding_value=-1)\n",
    "\n",
    "    print(\"Padded Sentences: Shape =\", padded_sentences.shape, \", Type =\", type(padded_sentences))\n",
    "    print(\"Padded Labels: Shape =\", padded_labels.shape, \", Type =\", type(padded_labels))\n",
    "\n",
    "    # Manually split the data\n",
    "    dataset_size = len(padded_sentences)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(0.8 * dataset_size))  # Ensure np is defined\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_indices, val_indices = indices[:split], indices[split:]\n",
    "\n",
    "    train_sentences = padded_sentences[train_indices]\n",
    "    val_sentences = padded_sentences[val_indices]\n",
    "    train_labels = padded_labels[train_indices]\n",
    "    val_labels = padded_labels[val_indices]\n",
    "\n",
    "    train_data = TensorDataset(train_sentences, train_labels)\n",
    "    val_data = TensorDataset(val_sentences, val_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Define the BiLSTM-CRF model\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim=100, hidden_dim=256):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)  # Ensure this outputs num_tags (tagset_size)\n",
    "        self.transitions = nn.Parameter(torch.randn(tagset_size, tagset_size))\n",
    "\n",
    "        self.start_transitions = nn.Parameter(torch.randn(tagset_size))\n",
    "        self.end_transitions = nn.Parameter(torch.randn(tagset_size))\n",
    "\n",
    "    def forward(self, sentences, labels=None, mask=None):\n",
    "        embeds = self.embedding(sentences)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        emissions = self.fc(lstm_out)  # Output: (batch_size, seq_len, num_tags)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self._compute_loss(emissions, labels, mask)\n",
    "            return loss\n",
    "        else:\n",
    "            # Apply Viterbi decoding for evaluation\n",
    "            return self._viterbi_decode(emissions, mask)  # Return the best paths\n",
    "\n",
    "    def _compute_loss(self, emissions, labels, mask):\n",
    "        gold_score = self._compute_score(emissions, labels, mask)\n",
    "        partition_score = self._compute_log_partition(emissions, mask)\n",
    "        return partition_score - gold_score\n",
    "\n",
    "    def _compute_score(self, emissions, labels, mask):\n",
    "        batch_size, seq_len = emissions.size(0), emissions.size(1)\n",
    "        score = self.start_transitions[labels[:, 0]]\n",
    "\n",
    "        for t in range(seq_len - 1):\n",
    "            score += emissions[torch.arange(batch_size), t, labels[:, t]] * mask[:, t]\n",
    "            score += self.transitions[labels[:, t], labels[:, t + 1]] * mask[:, t + 1]\n",
    "\n",
    "        score += emissions[torch.arange(batch_size), -1, labels[:, -1]] * mask[:, -1]\n",
    "        score += self.end_transitions[labels[:, -1]] * mask[:, -1]\n",
    "\n",
    "        return score.sum()\n",
    "\n",
    "    def _compute_log_partition(self, emissions, mask):\n",
    "        seq_len, num_tags = emissions.shape[1], emissions.shape[2]\n",
    "        batch_size = emissions.size(0)\n",
    "\n",
    "        alpha = self.start_transitions + emissions[:, 0]\n",
    "\n",
    "        for t in range(1, seq_len):\n",
    "            alpha_t = []\n",
    "            for tag in range(num_tags):\n",
    "                log_sum_exp = torch.logsumexp(alpha + self.transitions[:, tag], dim=1)\n",
    "                alpha_t.append(log_sum_exp)\n",
    "            alpha = torch.stack(alpha_t, dim=1) + emissions[:, t] * mask[:, t].unsqueeze(-1)\n",
    "\n",
    "        alpha += self.end_transitions\n",
    "        return torch.logsumexp(alpha, dim=1).sum()\n",
    "\n",
    "    def _viterbi_decode(self, emissions, mask):\n",
    "        seq_len, num_tags = emissions.shape[1], emissions.shape[2]\n",
    "        batch_size = emissions.size(0)\n",
    "\n",
    "        # Initialize Viterbi variables\n",
    "        viterbi_scores = self.start_transitions + emissions[:, 0]\n",
    "        backpointers = []\n",
    "\n",
    "        for t in range(1, seq_len):\n",
    "            viterbi_t = []\n",
    "            backpointer_t = []\n",
    "\n",
    "            for tag in range(num_tags):\n",
    "                scores = viterbi_scores + self.transitions[:, tag]\n",
    "                best_tag_id = torch.argmax(scores, dim=1)\n",
    "                viterbi_t.append(scores[torch.arange(batch_size), best_tag_id])\n",
    "                backpointer_t.append(best_tag_id)\n",
    "\n",
    "            viterbi_scores = torch.stack(viterbi_t, dim=1) + emissions[:, t] * mask[:, t].unsqueeze(-1)\n",
    "            backpointers.append(torch.stack(backpointer_t, dim=1))\n",
    "\n",
    "        best_last_tag = torch.argmax(viterbi_scores + self.end_transitions, dim=1)\n",
    "        best_path = [best_last_tag]\n",
    "\n",
    "        for backpointer in reversed(backpointers):\n",
    "            best_last_tag = backpointer[torch.arange(batch_size), best_last_tag]\n",
    "            best_path.append(best_last_tag)\n",
    "\n",
    "        best_path.reverse()\n",
    "        return torch.stack(best_path, dim=1)\n",
    "\n",
    "# Define training and evaluation functions\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            sentences, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(sentences, labels=labels, mask=(labels != word2idx['<PAD>']).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss:.4f}\")\n",
    "        model.eval()\n",
    "        evaluate_model(model, val_loader)\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_labels = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            sentences, labels = batch\n",
    "            mask = (labels != word2idx['<PAD>']).float()\n",
    "            predictions = model(sentences, mask=mask)  # Get the predicted best paths\n",
    "\n",
    "            # The predictions should now be the best paths\n",
    "            for pred, true, m in zip(predictions, labels, mask):\n",
    "                valid_length = int(m.sum().item())  # Number of valid (non-padded) tokens\n",
    "                if valid_length > 0:\n",
    "                    total_correct += (pred[:valid_length] == true[:valid_length]).float().sum().item()\n",
    "                    total_labels += valid_length\n",
    "\n",
    "    accuracy = total_correct / total_labels if total_labels > 0 else 0\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Prepare the data\n",
    "file_path = r\"C:\\Users\\Kaushik Kadium\\Downloads\\original_cleaned\"  \n",
    "# Update the path as necessary\n",
    "sentences, labels = extract_data(file_path)\n",
    "print(f\"Extracted {len(sentences)} sentences and {len(labels)} label sets\")\n",
    "\n",
    "# Select only a subset of sentences for training (modify as needed)\n",
    "#sentences = sentences[:3000]\n",
    "#labels = labels[:3000]\n",
    "\n",
    "# Build vocabularies and encode sentences and labels\n",
    "word2idx, tag2idx = build_vocab(sentences, labels)\n",
    "idx2word = {v: k for k, v in word2idx.items()}  # For decoding sentences later\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}    # For decoding labels later\n",
    "encoded_sentences = [encode_sentence(s, word2idx) for s in sentences]\n",
    "encoded_labels = [encode_labels(l, tag2idx) for l in labels]\n",
    "\n",
    "# Truncate and pad sequences\n",
    "MAX_SEQ_LEN = 379\n",
    "encoded_sentences = truncate_sequences(encoded_sentences, MAX_SEQ_LEN)\n",
    "encoded_labels = truncate_sequences(encoded_labels, MAX_SEQ_LEN)\n",
    "\n",
    "# Balance dataset based on label distribution\n",
    "label_distribution = calculate_label_distribution(encoded_labels, tag2idx)\n",
    "target_count_per_class = min(label_distribution.values())  # Target the minimum count class for balance\n",
    "\n",
    "balanced_sentences, balanced_labels = balance_dataset(sentences, labels, label_distribution, target_count_per_class)\n",
    "\n",
    "# Encode and truncate balanced data\n",
    "encoded_sentences = [encode_sentence(s, word2idx) for s in balanced_sentences]\n",
    "encoded_labels = [encode_labels(l, tag2idx) for l in balanced_labels]\n",
    "encoded_sentences = truncate_sequences(encoded_sentences, MAX_SEQ_LEN)\n",
    "encoded_labels = truncate_sequences(encoded_labels, MAX_SEQ_LEN)\n",
    "\n",
    "# Prepare data loaders\n",
    "train_loader, val_loader = prepare_dataloaders(encoded_sentences, encoded_labels)\n",
    "print(\"Data preprocessing done!\")\n",
    "\n",
    "# Create the model\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)\n",
    "model = BiLSTM_CRF(vocab_size, tagset_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858c949-3cfd-4923-bb9c-4b3398876f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Function to load test sentences from a file\n",
    "def load_test_sentences(file_path):\n",
    "    test_sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            sentence = line.strip().split('\\t')[0]  # Extract the sentence part\n",
    "            test_sentences.append(sentence)\n",
    "    return test_sentences\n",
    "\n",
    "# Prediction Code for CaRB\n",
    "def generate_predictions_for_carb(model, test_sentences, word2idx, idx2word):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence in test_sentences:\n",
    "            # Encode sentence into word indices\n",
    "            encoded_sentence = torch.tensor([word2idx.get(word, word2idx['<PAD>']) for word in sentence.split()]).unsqueeze(0)\n",
    "\n",
    "            # Generate mask based on valid tokens\n",
    "            mask = (encoded_sentence != word2idx['<PAD>']).float()\n",
    "\n",
    "            # Generate predictions using the model with Viterbi decoding\n",
    "            predictions = model(encoded_sentence, mask=mask)\n",
    "\n",
    "            # Decode predictions and map back to words\n",
    "            predictions = predictions.squeeze(0).tolist()\n",
    "            words = [idx2word[word_idx] for word_idx in encoded_sentence.squeeze(0).tolist() if word_idx != word2idx['<PAD>']]\n",
    "\n",
    "            # Ensure length of predictions and words are the same\n",
    "            if len(predictions) > len(words):\n",
    "                predictions = predictions[:len(words)]\n",
    "            elif len(predictions) < len(words):\n",
    "                words = words[:len(predictions)]\n",
    "\n",
    "            # Extract relation and arguments from predictions\n",
    "            relation, arg1, arg2, additional_args = [], [], [], []\n",
    "\n",
    "            for idx, label in enumerate(predictions):\n",
    "                tag = idx2tag.get(label, 'NONE')\n",
    "\n",
    "                if tag == \"REL\":\n",
    "                    relation.append(words[idx])\n",
    "                elif tag == \"ARG1\":\n",
    "                    arg1.append(words[idx])\n",
    "                elif tag == \"ARG2\":\n",
    "                    arg2.append(words[idx])\n",
    "                else:\n",
    "                    additional_args.append(words[idx])\n",
    "\n",
    "            # Skip if no valid extraction was found\n",
    "            if relation and arg1 and arg2:\n",
    "                # Join relation and arguments into the required format\n",
    "                formatted_line = f\"{sentence}\\t1.00\\t{' '.join(relation)}\\t{' '.join(arg1)}\\t{' '.join(arg2)}\"\n",
    "                if additional_args:\n",
    "                    formatted_line += f\"\\t{' '.join(additional_args)}\"\n",
    "\n",
    "                all_predictions.append(formatted_line)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "# Test Sentences Prediction\n",
    "test_file_path = r\"C:\\Users\\Kaushik Kadium\\Documents\\Python Scripts\\CaRB\\data\\test.txt\"  # Path to your test file\n",
    "test_sentences = load_test_sentences(test_file_path)\n",
    "\n",
    "# Generate predictions for CaRB\n",
    "test_predictions = generate_predictions_for_carb(model, test_sentences, word2idx, idx2word)\n",
    "\n",
    "# Save the predictions to a file in the format expected by CaRB\n",
    "output_file_path = r\"your_output.txt\"\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    for line in test_predictions:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"Predictions saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7503aa-2b05-4f50-a2a1-e615764e25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_ground_truth(file_path):\n",
    "    \"\"\"Load the ground truth extractions from the gold test file.\"\"\"\n",
    "    ground_truths = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) >= 5:\n",
    "                ground_truths.append({\n",
    "                    'sentence': row[0],\n",
    "                    'relation': row[2].split(),\n",
    "                    'arg1': row[3].split(),\n",
    "                    'arg2': row[4].split()\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping invalid row (less than 5 columns): {row}\")\n",
    "    return ground_truths\n",
    "\n",
    "def load_model_predictions(file_path):\n",
    "    \"\"\"Load the model's predicted extractions from the generated output file.\"\"\"\n",
    "    predictions = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) >= 5:\n",
    "                predictions.append({\n",
    "                    'sentence': row[0],\n",
    "                    'relation': row[2].split(),\n",
    "                    'arg1': row[3].split(),\n",
    "                    'arg2': row[4].split()\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping invalid row (less than 5 columns): {row}\")\n",
    "    return predictions\n",
    "\n",
    "def error_analysis(predictions, ground_truths):\n",
    "    \"\"\"Perform error analysis between predictions and ground truth extractions.\"\"\"\n",
    "    incorrect_extractions = {\n",
    "        \"Correct relation phrase, incorrect arguments\": 0,\n",
    "        \"Non-contiguous relation phrase\": 0,\n",
    "        \"Overspecified relation phrase\": 0,\n",
    "        \"N-ary relations (more than two arguments)\": 0,\n",
    "        \"Imperative verb used in relation\": 0,\n",
    "        \"Other errors\": 0\n",
    "    }\n",
    "\n",
    "    missed_extractions = {\n",
    "        \"Could not identify correct arguments\": 0,\n",
    "        \"Relation filtered out by lexical constraint\": 0,\n",
    "        \"POS/chunking error\": 0,\n",
    "        \"Identified a more specific relation\": 0,\n",
    "        \"Other errors\": 0\n",
    "    }\n",
    "\n",
    "    mismatched_sentences = []  # To track sentences with errors\n",
    "    incorrect_sentences = {key: [] for key in incorrect_extractions}  # Store sentences for each incorrect extraction type\n",
    "    missed_sentences = {key: [] for key in missed_extractions}  # Store sentences for each missed extraction type\n",
    "\n",
    "    for truth in ground_truths:\n",
    "        matching_pred = next((pred for pred in predictions if pred['sentence'] == truth['sentence']), None)\n",
    "        \n",
    "        if not matching_pred:\n",
    "            # No prediction made for this sentence (missed entirely)\n",
    "            missed_extractions[\"Relation filtered out by lexical constraint\"] += 1\n",
    "            missed_sentences[\"Relation filtered out by lexical constraint\"].append(truth['sentence'])\n",
    "            continue\n",
    "        \n",
    "        pred_relation = set(matching_pred['relation'])\n",
    "        pred_arg1 = set(matching_pred['arg1'])\n",
    "        pred_arg2 = set(matching_pred['arg2'])\n",
    "\n",
    "        truth_relation = set(truth['relation'])\n",
    "        truth_arg1 = set(truth['arg1'])\n",
    "        truth_arg2 = set(truth['arg2'])\n",
    "\n",
    "        # Additional argument checking for n-ary relations\n",
    "        truth_arg_count = len([truth['arg1'], truth['arg2']])\n",
    "        pred_arg_count = len([matching_pred['arg1'], matching_pred['arg2']])\n",
    "\n",
    "        if truth_arg_count > 2 or pred_arg_count > 2:\n",
    "            incorrect_extractions[\"N-ary relations (more than two arguments)\"] += 1\n",
    "            incorrect_sentences[\"N-ary relations (more than two arguments)\"].append(truth['sentence'])\n",
    "\n",
    "        mismatch_info = {\"sentence\": truth['sentence'], \"error_type\": None}\n",
    "\n",
    "        # Check for imperative verbs in relations\n",
    "        if pred_relation and pred_relation.intersection({\"please\", \"do\", \"go\", \"stop\", \"give\", \"help\"}):\n",
    "            incorrect_extractions[\"Imperative verb used in relation\"] += 1\n",
    "            incorrect_sentences[\"Imperative verb used in relation\"].append(truth['sentence'])\n",
    "\n",
    "        # Incorrect extraction cases\n",
    "        if pred_relation == truth_relation:\n",
    "            if pred_arg1 != truth_arg1 or pred_arg2 != truth_arg2:\n",
    "                incorrect_extractions[\"Correct relation phrase, incorrect arguments\"] += 1\n",
    "                incorrect_sentences[\"Correct relation phrase, incorrect arguments\"].append(truth['sentence'])\n",
    "        else:\n",
    "            if len(pred_relation.intersection(truth_relation)) > 0:\n",
    "                incorrect_extractions[\"Non-contiguous relation phrase\"] += 1\n",
    "                incorrect_sentences[\"Non-contiguous relation phrase\"].append(truth['sentence'])\n",
    "            elif len(pred_relation) > len(truth_relation):\n",
    "                incorrect_extractions[\"Overspecified relation phrase\"] += 1\n",
    "                incorrect_sentences[\"Overspecified relation phrase\"].append(truth['sentence'])\n",
    "            else:\n",
    "                incorrect_extractions[\"Other errors\"] += 1\n",
    "                incorrect_sentences[\"Other errors\"].append(truth['sentence'])\n",
    "\n",
    "        # Missed extraction cases\n",
    "        if not pred_relation and truth_relation:\n",
    "            missed_extractions[\"Relation filtered out by lexical constraint\"] += 1\n",
    "            missed_sentences[\"Relation filtered out by lexical constraint\"].append(truth['sentence'])\n",
    "        if not pred_arg1 and truth_arg1:\n",
    "            missed_extractions[\"Could not identify correct arguments\"] += 1\n",
    "            missed_sentences[\"Could not identify correct arguments\"].append(truth['sentence'])\n",
    "        if not pred_arg2 and truth_arg2:\n",
    "            missed_extractions[\"Could not identify correct arguments\"] += 1\n",
    "            missed_sentences[\"Could not identify correct arguments\"].append(truth['sentence'])\n",
    "\n",
    "        # Check if predicted relation is more specific than ground truth relation\n",
    "        if pred_relation and truth_relation and len(pred_relation) > len(truth_relation):\n",
    "            missed_extractions[\"Identified a more specific relation\"] += 1\n",
    "            missed_sentences[\"Identified a more specific relation\"].append(truth['sentence'])\n",
    "\n",
    "        # Add mismatched sentence for reporting\n",
    "        if mismatch_info[\"error_type\"]:\n",
    "            mismatched_sentences.append(mismatch_info)\n",
    "\n",
    "    return incorrect_extractions, missed_extractions, mismatched_sentences, incorrect_sentences, missed_sentences\n",
    "\n",
    "# Load ground truth and predictions\n",
    "ground_truth_file = r\"C:\\Users\\Kaushik Kadium\\Documents\\Python Scripts\\CaRB\\data\\gold\\test.tsv\"\n",
    "prediction_file = r\"C:\\Users\\Kaushik Kadium\\Documents\\Python Scripts\\CaRB\\your_output.txt\"\n",
    "\n",
    "ground_truths = load_ground_truth(ground_truth_file)\n",
    "predictions = load_model_predictions(prediction_file)\n",
    "\n",
    "# Run the error analysis\n",
    "incorrect_extractions, missed_extractions, mismatched_sentences, incorrect_sentences, missed_sentences = error_analysis(predictions, ground_truths)\n",
    "\n",
    "# Print analysis results\n",
    "print(\"Incorrect Extractions:\")\n",
    "for key, value in incorrect_extractions.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nMissed Extractions:\")\n",
    "for key, value in missed_extractions.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Print 5 example sentences for each error type in incorrect extractions\n",
    "print(\"\\nExample Sentences for Incorrect Extractions:\")\n",
    "for error_type, sentences in incorrect_sentences.items():\n",
    "    print(f\"\\n{error_type} (Showing up to 5 examples):\")\n",
    "    for sentence in sentences[:5]:\n",
    "        print(f\"- {sentence}\")\n",
    "\n",
    "# Print 5 example sentences for each error type in missed extractions\n",
    "print(\"\\nExample Sentences for Missed Extractions:\")\n",
    "for error_type, sentences in missed_sentences.items():\n",
    "    print(f\"\\n{error_type} (Showing up to 5 examples):\")\n",
    "    for sentence in sentences[:5]:\n",
    "        print(f\"- {sentence}\")\n",
    "\n",
    "# Print mismatched sentences for analysis\n",
    "print(\"\\nMismatched Sentences:\")\n",
    "for mismatch in mismatched_sentences:\n",
    "    print(f\"Sentence: {mismatch['sentence']}, Error Type: {mismatch['error_type']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310_env)",
   "language": "python",
   "name": "py310_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
